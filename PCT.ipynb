{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of Point Cloud Transformer (PCT) in Tensorflow, based on its original implementation.\n",
        "\n",
        "Original repo: https://github.com/qinglew/PointCloudTransformer/\n",
        "\n",
        "Paper: https://link.springer.com/article/10.1007/s41095-021-0229-5"
      ],
      "metadata": {
        "id": "Audxvl5WELyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmkVUPeSEIzM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "import tensorflow.keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive PCT Classification"
      ],
      "metadata": {
        "id": "hfvRxYdLLha4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(tf.keras.layers.Layer):\n",
        "  '''\n",
        "  Input: (B, N, in_channels)\n",
        "  Output: (B, N, out_channels)\n",
        "  '''\n",
        "  def __init__(self, in_channels=3, out_channels=128, **kwargs):\n",
        "    self.input_dim = in_channels\n",
        "    self.output_dim = out_channels\n",
        "    super(Embedding, self).__init__(**kwargs)\n",
        "\n",
        "    self.conv1 = tf.keras.layers.Conv1D(out_channels, kernel_size=1, use_bias=False)\n",
        "    self.conv2 = tf.keras.layers.Conv1D(out_channels, kernel_size=1, use_bias=False)\n",
        "\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.relu1 = tf.keras.layers.Activation(\"relu\")\n",
        "    self.relu2 = tf.keras.layers.Activation(\"relu\")\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.relu2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "esj3_zp7Eqrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SA(tf.keras.layers.Layer):\n",
        "  '''\n",
        "  Input: (B, N, out_channels)\n",
        "  Output: (B, N, out_channels)\n",
        "  '''\n",
        "  def __init__(self, channels=128, **kwargs):\n",
        "    super(SA, self).__init__(**kwargs)\n",
        "\n",
        "    self.da = channels // 4\n",
        "\n",
        "    self.q_conv = tf.keras.layers.Conv1D(channels // 4, kernel_size=1, use_bias=False)\n",
        "    self.k_conv = tf.keras.layers.Conv1D(channels // 4, kernel_size=1, use_bias=False)\n",
        "    self.v_conv = tf.keras.layers.Conv1D(channels, kernel_size=1)\n",
        "\n",
        "    self.trans_conv = tf.keras.layers.Conv1D(channels, kernel_size=1)\n",
        "    self.after_norm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.act = tf.keras.layers.Activation(\"relu\")\n",
        "    self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "  def call(self, x):\n",
        "    x_q = self.q_conv(x)\n",
        "    x_q = tf.transpose(x_q, perm=[0,2,1])\n",
        "    x_k = self.k_conv(x)\n",
        "    x_v = self.v_conv(x)\n",
        "\n",
        "    energy = tf.matmul(x_k, x_q) / (math.sqrt(self.da))\n",
        "    attention = self.softmax(energy)\n",
        "\n",
        "    x_s = tf.matmul(x_v, attention, transpose_a=True)\n",
        "    x_s = tf.transpose(x_s, perm=[0, 2, 1])\n",
        "    x_s = self.act(self.after_norm(self.trans_conv(x_s)))\n",
        "\n",
        "    x = x + x_s\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "SB2W_671KPAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NaivePCT(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(NaivePCT, self).__init__(**kwargs)\n",
        "\n",
        "    self.embedding = Embedding(3, 128)\n",
        "\n",
        "    self.sa1 = SA(128)\n",
        "    self.sa2 = SA(128)\n",
        "    self.sa3 = SA(128)\n",
        "    self.sa4 = SA(128)\n",
        "\n",
        "    self.conv1d = tf.keras.layers.Dense(1024)\n",
        "    self.bn = tf.keras.layers.BatchNormalization()\n",
        "    self.act = tf.keras.layers.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    x1 = self.sa1(x)\n",
        "    x2 = self.sa2(x1)\n",
        "    x3 = self.sa3(x2)\n",
        "    x4 = self.sa4(x3)\n",
        "    x = tf.concat([x1, x2, x3, x4], axis=1)\n",
        "\n",
        "    x = self.conv1d(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.act(x)\n",
        "\n",
        "    x_max = tf.math.reduce_max(x, axis=-1)\n",
        "    x_mean = tf.math.reduce_mean(x, axis=-1)\n",
        "\n",
        "    #return x, x_max, x_mean\n",
        "    return tf.concat([x_max, x_mean], axis=-1)"
      ],
      "metadata": {
        "id": "ISTQN2hTNA-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PCT_Naive_Classification(out_classes, batch_size=128):\n",
        "  inputs = tf.keras.layers.Input(shape=(1024,3), batch_size=batch_size)\n",
        "  x = NaivePCT()(inputs)\n",
        "\n",
        "  x = tf.keras.layers.Dense(512)(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  x = tf.keras.layers.Dense(256)(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(out_classes)(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=outputs, name='PCT_Naive_Classification')"
      ],
      "metadata": {
        "id": "DRrokClmPK7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sqrd_euclidean_distance_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Squared Euclidean distance loss\n",
        "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "    :param y_true: TensorFlow/Theano tensor\n",
        "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    return K.sum(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "model = PCT_Naive_Classification(6)\n",
        "\n",
        "# Compiling\n",
        "model.compile(\n",
        "  loss=sqrd_euclidean_distance_loss,\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "  metrics=[sqrd_euclidean_distance_loss],\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "D2ONlBi1Nsmx",
        "outputId": "cc519a02-4a22-4603-9bcf-ae046d84cdef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"PCT_Naive_Classification\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"PCT_Naive_Classification\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ naive_pct_8 (\u001b[38;5;33mNaivePCT\u001b[0m)          │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m8192\u001b[0m)            │       \u001b[38;5;34m320,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │     \u001b[38;5;34m4,194,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_75          │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_66 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_76          │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_67 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m6\u001b[0m)               │         \u001b[38;5;34m1,542\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ naive_pct_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NaivePCT</span>)          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_75          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_76          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,651,654\u001b[0m (17.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,651,654</span> (17.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,646,534\u001b[0m (17.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,646,534</span> (17.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,120\u001b[0m (20.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> (20.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCT Classification"
      ],
      "metadata": {
        "id": "YrDstb60Lk1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "UKLRY6YMN-AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def farthest_point_sampling(npoint, xyz):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: pointcloud data, [B, N, 3]\n",
        "        npoint: number of samples\n",
        "    Return:\n",
        "        centroids: sampled pointcloud index, [B, npoint]\n",
        "    \"\"\"\n",
        "    B, N, C = xyz.shape\n",
        "    centroids = tf.TensorArray(dtype=tf.int32, size=npoint, dynamic_size=False)\n",
        "    distance = tf.ones((B, N), dtype=tf.float32) * 1e10\n",
        "    farthest = tf.random.uniform((B,), minval=0, maxval=N, dtype=tf.int32)\n",
        "    batch_indices = tf.range(B, dtype=tf.int32)\n",
        "\n",
        "    def loop_body(i, centroids, distance, farthest):\n",
        "        centroids = centroids.write(i, farthest)\n",
        "        centroid = tf.gather(xyz, farthest, batch_dims=1)[:, tf.newaxis, :]  # [B, 1, 3]\n",
        "        dist = tf.reduce_sum((xyz - centroid) ** 2, axis=-1)  # [B, N]\n",
        "        mask = dist < distance\n",
        "        distance = tf.where(mask, dist, distance)\n",
        "        farthest = tf.argmax(distance, axis=-1, output_type=tf.int32)\n",
        "        return i + 1, centroids, distance, farthest\n",
        "\n",
        "    _, centroids, _, _ = tf.while_loop(\n",
        "        lambda i, *args: i < npoint,\n",
        "        loop_body,\n",
        "        [0, centroids, distance, farthest]\n",
        "    )\n",
        "\n",
        "    return tf.transpose(centroids.stack(), perm=[1, 0])  # [B, npoint]\n",
        "\n",
        "def pairwise_distance(point_cloud):\n",
        "  \"\"\"Compute pairwise distance of a point cloud.\n",
        "\n",
        "  Args:\n",
        "    point_cloud: tensor (batch_size, num_points, num_dims)\n",
        "\n",
        "  Returns:\n",
        "    pairwise distance: (batch_size, num_points, num_points)\n",
        "  \"\"\"\n",
        "  og_batch_size = point_cloud.shape[0]\n",
        "  point_cloud = tf.squeeze(point_cloud)\n",
        "  if og_batch_size == 1:\n",
        "    point_cloud = tf.expand_dims(point_cloud, 0)\n",
        "\n",
        "  point_cloud_transpose = tf.transpose(point_cloud, perm=[0, 2, 1])\n",
        "  point_cloud_inner = tf.matmul(point_cloud, point_cloud_transpose)\n",
        "  point_cloud_inner = -2*point_cloud_inner\n",
        "  point_cloud_square = tf.reduce_sum(tf.square(point_cloud), axis=-1, keepdims=True)\n",
        "  point_cloud_square_tranpose = tf.transpose(point_cloud_square, perm=[0, 2, 1])\n",
        "  return point_cloud_square + point_cloud_inner + point_cloud_square_tranpose\n",
        "\n",
        "def knn(adj_matrix, k=16):\n",
        "  \"\"\"Get KNN based on the pairwise distance.\n",
        "  Args:\n",
        "    pairwise distance: (batch_size, num_points, num_points)\n",
        "    k: int\n",
        "\n",
        "  Returns:\n",
        "    nearest neighbors: (batch_size, num_points, k)\n",
        "  \"\"\"\n",
        "  neg_adj = -adj_matrix\n",
        "  _, nn_idx = tf.nn.top_k(neg_adj, k=k)\n",
        "  return nn_idx\n",
        "\n",
        "def index_points(points, idx):\n",
        "    \"\"\"\n",
        "\n",
        "    Input:\n",
        "        points: input points data, [B, N, C]\n",
        "        idx: sample index data, [B, S]\n",
        "    Return:\n",
        "        new_points:, indexed points data, [B, S, C]\n",
        "    \"\"\"\n",
        "    B, _, _ = points.shape\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = tf.range(B, dtype=tf.int32)\n",
        "    batch_indices = tf.reshape(batch_indices, shape=view_shape)  # reshape to view_shape\n",
        "    batch_indices = tf.tile(batch_indices, multiples=repeat_shape)  # repeat according to repeat_shape\n",
        "    new_points = tf.gather(points, idx, axis=1, batch_dims=1)\n",
        "    return new_points\n",
        "\n",
        "def square_distance(src, dst):\n",
        "    \"\"\"\n",
        "    Compute squared distances between two point sets.\n",
        "    Input:\n",
        "        src: source points, [B, N, C]\n",
        "        dst: target points, [B, M, C]\n",
        "    Output:\n",
        "        dist: squared distances, [B, N, M]\n",
        "    \"\"\"\n",
        "    dist = tf.reduce_sum(src**2, axis=-1, keepdims=True) - \\\n",
        "           2 * tf.matmul(src, tf.transpose(dst, perm=[0, 2, 1])) + \\\n",
        "           tf.transpose(tf.reduce_sum(dst**2, axis=-1, keepdims=True), perm=[0, 2, 1])\n",
        "    return tf.maximum(dist, 0)  # Avoid small negative values due to floating-point errors\n",
        "\n",
        "def query_ball_point(radius, cardinality, xyz, new_xyz):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        radius: local region radius\n",
        "        cardinality: max sample number in local region\n",
        "        xyz: all points, [B, N, 3]\n",
        "        new_xyz: query points, [B, S, 3]\n",
        "    Return:\n",
        "        group_idx: grouped points index, [B, S, cardinality]\n",
        "    \"\"\"\n",
        "    B, N, C = xyz.shape\n",
        "    S = tf.shape(new_xyz)[1]\n",
        "\n",
        "    # Generate group indices [1, 1, N] -> [B, S, N]\n",
        "    group_idx = tf.tile(tf.range(N, dtype=tf.int32)[tf.newaxis, tf.newaxis, :], [B, S, 1])\n",
        "\n",
        "    # Compute squared distances between new_xyz and xyz\n",
        "    sqrdists = square_distance(new_xyz, xyz)\n",
        "\n",
        "    # Mask out points outside the radius\n",
        "    group_idx = tf.where(sqrdists > radius**2, N, group_idx)\n",
        "\n",
        "    # Sort and select the top cardinality points\n",
        "    group_idx = tf.sort(group_idx, axis=-1)[:, :, :cardinality]\n",
        "\n",
        "    # Handle cases where there are fewer than cardinality points within the radius\n",
        "    group_first = tf.tile(group_idx[:, :, 0:1], [1, 1, cardinality])  # Repeat the first valid index\n",
        "    mask = tf.equal(group_idx, N)\n",
        "    group_idx = tf.where(mask, group_first, group_idx)\n",
        "\n",
        "    return group_idx\n",
        "\n",
        "def sample_and_group(xyz, cardinality, ball_query=False, radius=0.2, use_knn=True, k=32):\n",
        "    '''\n",
        "    Input:\n",
        "        k (nsample): int32\n",
        "        radius: float32\n",
        "        cardinality (npoint): int32\n",
        "        xyz: (batch_size, ndataset, 3) TF tensor (original points)\n",
        "        knn: bool, if True use kNN instead of radius search\n",
        "    Output:\n",
        "        new_xyz: (batch_size, cardinality, 3) TF tensor (sampled points)\n",
        "        new_points: (batch_size, cardinality, k, 3) TF tensor (grouped points relative to sampled points)\n",
        "        idx: (batch_size, cardinality, k) TF tensor, indices of local points as in ndataset points\n",
        "        grouped_xyz: (batch_size, cardinality, k, 3) TF tensor, normalized point XYZs\n",
        "            (subtracted by seed point XYZ) in local regions\n",
        "    '''\n",
        "    batch_size, num_points, num_dims = xyz.shape\n",
        "    # farthest point sampling to get centroids\n",
        "    fps_idx = farthest_point_sampling(cardinality, xyz) # [B, cardinality]\n",
        "\n",
        "    # gather points corresponding to centroids\n",
        "    new_xyz = tf.gather(xyz, fps_idx, batch_dims=1) # [B, cardinality, C]\n",
        "\n",
        "    if ball_query:\n",
        "      idx = query_ball_point(radius, k, xyz, new_xyz)\n",
        "\n",
        "    elif use_knn:\n",
        "      # compute pairwise distance between sampled points and original points\n",
        "      sqrdists = square_distance(new_xyz, xyz) # [B, cardinality, num_points]\n",
        "\n",
        "      # get k nearest neighbors from original points for each sampled point\n",
        "      neg_sqrdists = -sqrdists\n",
        "      _, idx = tf.nn.top_k(neg_sqrdists, k=k) # [B, cardinality, k]\n",
        "\n",
        "    # gather the features (coordinates) of the k nearest neighbors from the original xyz\n",
        "    batch_indices = tf.tile(tf.range(batch_size)[:, tf.newaxis, tf.newaxis], [1, cardinality, k])\n",
        "    grouped_xyz = tf.gather_nd(xyz, tf.stack([batch_indices, idx], axis=-1)) # [B, cardinality, k, C]\n",
        "\n",
        "    # Normalization (subtract centroid)\n",
        "    grouped_xyz -= tf.tile(tf.expand_dims(new_xyz, 2), [1, 1, k, 1]) # [B, cardinality, k, C]\n",
        "\n",
        "    new_points = grouped_xyz # For this layer, new_points are the grouped and normalized xyz\n",
        "\n",
        "    return new_xyz, new_points, idx, grouped_xyz"
      ],
      "metadata": {
        "id": "EhQAF5ltZ29M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "eLjg-_2DOAHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SG(tf.keras.layers.Layer):\n",
        "  def __init__(self, s, in_channels, out_channels, **kwargs):\n",
        "    super(SG, self).__init__(**kwargs)\n",
        "\n",
        "    self.s = s\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "    self.conv1 = tf.keras.layers.Conv1D(out_channels, kernel_size=1, use_bias=False)\n",
        "    self.conv2 = tf.keras.layers.Conv1D(out_channels, kernel_size=1, use_bias=False)\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "    self.relu1 = tf.keras.layers.Activation(\"relu\")\n",
        "    self.relu2 = tf.keras.layers.Activation(\"relu\")\n",
        "\n",
        "  def call(self, coords):\n",
        "    new_xyz, new_feature, _, _ = sample_and_group(xyz=coords, cardinality=self.s, use_knn=True, k=32)\n",
        "    b, s, k, d = new_feature.shape\n",
        "    new_feature = tf.transpose(new_feature, perm=[0, 1, 3, 2])\n",
        "    new_feature = tf.reshape(new_feature, [-1, d, k])\n",
        "    batch_size = new_feature.shape[0]\n",
        "    new_feature = self.relu1(self.bn1(self.conv1(new_feature)))\n",
        "    new_feature = self.relu2(self.bn2(self.conv2(new_feature)))\n",
        "    new_feature = tf.math.reduce_max(new_feature, axis=-1)\n",
        "    new_feature = tf.reshape(new_feature, [b, s, -1])\n",
        "    new_feature = tf.transpose(new_feature, perm=[0, 2, 1])\n",
        "\n",
        "    return new_xyz, new_feature"
      ],
      "metadata": {
        "id": "m3P_yo97NJq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeighborEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, samples=[512, 256], **kwargs):\n",
        "    super(NeighborEmbedding, self).__init__(**kwargs)\n",
        "\n",
        "    self.conv1 = tf.keras.layers.Conv1D(64, kernel_size=1, use_bias=False)\n",
        "    self.conv2 = tf.keras.layers.Conv1D(64, kernel_size=1, use_bias=False)\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "    self.relu1 = tf.keras.layers.Activation(\"relu\")\n",
        "    self.relu2 = tf.keras.layers.Activation(\"relu\")\n",
        "\n",
        "    self.sg1 = SG(s=samples[0], in_channels=128, out_channels=128)\n",
        "    self.sg2 = SG(s=samples[1], in_channels=256, out_channels=256)\n",
        "\n",
        "  def call(self, x):\n",
        "    '''\n",
        "    Input: [B, N, 3]\n",
        "    Output: [B, 256, 256]\n",
        "    '''\n",
        "    #xyz = tf.transpose(x, perm=[0, 2, 1])\n",
        "    features = self.relu1(self.bn1(self.conv1(x)))\n",
        "    features = self.relu2(self.bn2(self.conv2(features)))\n",
        "\n",
        "    new_xyz, new_features = self.sg1(features)\n",
        "    _, new_features2 = self.sg2(new_features)\n",
        "\n",
        "    return new_features2"
      ],
      "metadata": {
        "id": "LRPo_CdhLtdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OA(tf.keras.layers.Layer):\n",
        "  def __init__(self, channels, **kwargs):\n",
        "    super(OA, self).__init__(**kwargs)\n",
        "\n",
        "    self.q_conv = tf.keras.layers.Conv1D(channels // 4, kernel_size=1, use_bias=False)\n",
        "    self.k_conv = tf.keras.layers.Conv1D(channels // 4, kernel_size=1, use_bias=False)\n",
        "    self.v_conv = tf.keras.layers.Conv1D(channels, kernel_size=1)\n",
        "\n",
        "    self.trans_conv = tf.keras.layers.Conv1D(channels, kernel_size=1)\n",
        "    self.after_norm = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    self.act = tf.keras.layers.Activation(\"relu\")\n",
        "    self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "  def call(self, x):\n",
        "    x_q = self.q_conv(x)\n",
        "    x_q = tf.transpose(x_q, perm=[0,2,1])\n",
        "    x_k = self.k_conv(x)\n",
        "    x_v = self.v_conv(x)\n",
        "\n",
        "    energy = tf.matmul(x_k, x_q)\n",
        "    attention = self.softmax(energy)\n",
        "    attention = attention / (1e-9 + tf.reduce_sum(attention, axis=1, keepdims=True))\n",
        "\n",
        "    x_r = tf.matmul(x_v, attention, transpose_a=True)\n",
        "    x_r = tf.transpose(x_r, perm=[0,2,1])\n",
        "    x_r = self.act(self.after_norm(self.trans_conv(x - x_r)))\n",
        "    x = x + x_r\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "RVXJyTkycCpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PCT(tf.keras.layers.Layer):\n",
        "  def __init__(self, samples=[512, 256], **kwargs):\n",
        "    super(PCT, self).__init__(**kwargs)\n",
        "\n",
        "    self.neighbor_embedding = NeighborEmbedding(samples)\n",
        "\n",
        "    self.oa1 = OA(256)\n",
        "    self.oa2 = OA(256)\n",
        "    self.oa3 = OA(256)\n",
        "    self.oa4 = OA(256)\n",
        "\n",
        "    self.conv1d = tf.keras.layers.Dense(1024)\n",
        "    self.bn = tf.keras.layers.BatchNormalization()\n",
        "    self.act = tf.keras.layers.LeakyReLU(negative_slope=0.2)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.neighbor_embedding(x)\n",
        "\n",
        "    x1 = self.oa1(x)\n",
        "    x2 = self.oa2(x1)\n",
        "    x3 = self.oa3(x2)\n",
        "    x4 = self.oa4(x3)\n",
        "\n",
        "    x = tf.concat([x, x1, x2, x3, x4], axis=1)\n",
        "\n",
        "    x = self.conv1d(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.act(x)\n",
        "\n",
        "    x_max = tf.math.reduce_max(x, axis=-1)\n",
        "    x_mean = tf.math.reduce_mean(x, axis=-1)\n",
        "\n",
        "    #return x, x_max, x_mean\n",
        "    return tf.concat([x_max, x_mean], axis=-1)"
      ],
      "metadata": {
        "id": "_cDUKer3eD70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PCT_Classification(out_classes, batch_size=128):\n",
        "  inputs = tf.keras.layers.Input(shape=(1024,3), batch_size=batch_size)\n",
        "  x = PCT()(inputs)\n",
        "\n",
        "  x = tf.keras.layers.Dense(512)(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  x = tf.keras.layers.Dense(256)(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation(\"relu\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(out_classes)(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=outputs, name='PCT_Classification')"
      ],
      "metadata": {
        "id": "kaB60cGTfLFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sqrd_euclidean_distance_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Squared Euclidean distance loss\n",
        "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "    :param y_true: TensorFlow/Theano tensor\n",
        "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    return K.sum(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "model = PCT_Classification(6)\n",
        "\n",
        "# Compiling\n",
        "model.compile(\n",
        "  loss=sqrd_euclidean_distance_loss,\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "  metrics=[sqrd_euclidean_distance_loss],\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "78flxvOOfWNn",
        "outputId": "1400e0c0-b241-4b59-d28b-dcae04a8e17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"PCT_Classification\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"PCT_Classification\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pct (\u001b[38;5;33mPCT\u001b[0m)                       │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m5120\u001b[0m)            │     \u001b[38;5;34m1,030,848\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │     \u001b[38;5;34m2,621,952\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_10 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_11 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m6\u001b[0m)               │         \u001b[38;5;34m1,542\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pct (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PCT</span>)                       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5120</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,030,848</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,621,952</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,788,742\u001b[0m (14.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,788,742</span> (14.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,781,318\u001b[0m (14.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,781,318</span> (14.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,424\u001b[0m (29.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,424</span> (29.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}